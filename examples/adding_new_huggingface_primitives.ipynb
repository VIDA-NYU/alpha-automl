{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the class `AutoMLClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_automl import AutoMLClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Pipelines for CSV Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are generating pipelines for a CSV dataset. The sentiment dataset is used for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'tmp/'\n",
    "train_dataset = pd.read_csv('datasets/sentiment/train_data.csv')\n",
    "test_dataset = pd.read_csv('datasets/sentiment/test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the target column from the features for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Grenada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Guatemala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text Time of Tweet  \\\n",
       "0                    I`d have responded, if I were going       morning   \n",
       "1          Sooo SAD I will miss you here in San Diego!!!          noon   \n",
       "2                              my boss is bullying me...         night   \n",
       "3                         what interview! leave me alone       morning   \n",
       "4       Sons of ****, why couldn`t they put them on t...          noon   \n",
       "...                                                  ...           ...   \n",
       "27476   wish we could come see u on Denver  husband l...         night   \n",
       "27477   I`ve wondered about rake to.  The client has ...       morning   \n",
       "27478   Yay good for both of you. Enjoy the break - y...          noon   \n",
       "27479                         But it was worth it  ****.         night   \n",
       "27480     All this flirting going on - The ATG smiles...       morning   \n",
       "\n",
       "      Age of User      Country  \n",
       "0            0-20  Afghanistan  \n",
       "1           21-30      Albania  \n",
       "2           31-45      Algeria  \n",
       "3           46-60      Andorra  \n",
       "4           60-70       Angola  \n",
       "...           ...          ...  \n",
       "27476       31-45        Ghana  \n",
       "27477       46-60       Greece  \n",
       "27478       60-70      Grenada  \n",
       "27479      70-100    Guatemala  \n",
       "27480        0-20       Guinea  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = 'sentiment'\n",
    "X_train = train_dataset.drop(columns=[target_column])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the target column for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment\n",
       "0       neutral\n",
       "1      negative\n",
       "2      negative\n",
       "3      negative\n",
       "4      negative\n",
       "...         ...\n",
       "27476  negative\n",
       "27477  negative\n",
       "27478  positive\n",
       "27479  positive\n",
       "27480   neutral\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_dataset[[target_column]]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding New Primitives into AlphaAutoML's Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLClassifier(output_path, time_bound=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: xlm-roberta-base\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/xlm-roberta-base HTTP/1.1\" 200 3217\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/77de1f7a7e5e737aead1cd880979d4f1b3af6668/.gitattributes HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/77de1f7a7e5e737aead1cd880979d4f1b3af6668/README.md HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.onnx HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/77de1f7a7e5e737aead1cd880979d4f1b3af6668/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json HTTP/1.1\" 200 0\n",
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /Users/rlopez/.cache/torch/sentence_transformers/xlm-roberta-base. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/rlopez/.cache/torch/sentence_transformers/xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "from alpha_automl.base_primitive import BasePrimitive\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "embedder = SentenceTransformer('xlm-roberta-base')\n",
    "\n",
    "class MyEmbedder(BasePrimitive):\n",
    "    # If running it in Windows or CUDA environment, this implementation should be in an external module.\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, texts):\n",
    "        text_list = texts.tolist()\n",
    "        embeddings = embedder.encode(text_list)\n",
    "\n",
    "        return np.array(embeddings)\n",
    "\n",
    "my_embedder = MyEmbedder()\n",
    "automl.add_primitives([(my_embedder, 'TEXT_ENCODER')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching  Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datamart_profiler.core:Setting column names from header\n",
      "INFO:datamart_profiler.core:Identifying types, 4 columns...\n",
      "INFO:datamart_profiler.core:Processing column 0 'text'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datamart_profiler.core:Column type http://schema.org/Text [http://schema.org/Text]\n",
      "INFO:datamart_profiler.core:Processing column 1 'Time of Tweet'...\n",
      "INFO:datamart_profiler.core:Column type http://schema.org/Text [http://schema.org/Enumeration]\n",
      "INFO:datamart_profiler.core:Processing column 2 'Age of User'...\n",
      "INFO:datamart_profiler.core:Column type http://schema.org/Text [http://schema.org/Enumeration]\n",
      "INFO:datamart_profiler.core:Processing column 3 'Country'...\n",
      "INFO:datamart_profiler.core:Column type http://schema.org/Text [http://schema.org/Enumeration]\n",
      "INFO:alpha_automl.data_profiler:Results of profiling data: non-numeric features = dict_keys(['TEXT_ENCODER', 'CATEGORICAL_ENCODER']), useless columns = [], missing values = True\n",
      "INFO:alpha_automl.utils:Sampling down data from 27481 to 2000\n",
      "INFO:alpha_automl.pipeline_synthesis.setup_search:Creating a manual grammar\n",
      "INFO:alpha_automl.primitive_loader:Hierarchy of all primitives loaded\n",
      "INFO:alpha_automl.grammar_loader:Creating task grammar for task CLASSIFICATION_TASK\n",
      "INFO:alpha_automl.grammar_loader:Task grammar: Grammar with 31 productions (start state = S)\n",
      "    S -> IMPUTATION ENCODERS FEATURE_SCALING FEATURE_SELECTION CLASSIFICATION\n",
      "    ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "    IMPUTATION -> 'sklearn.impute.SimpleImputer'\n",
      "    FEATURE_SCALING -> 'sklearn.preprocessing.MaxAbsScaler'\n",
      "    FEATURE_SCALING -> 'sklearn.preprocessing.RobustScaler'\n",
      "    FEATURE_SCALING -> 'sklearn.preprocessing.StandardScaler'\n",
      "    FEATURE_SCALING -> 'E'\n",
      "    FEATURE_SELECTION -> 'sklearn.feature_selection.GenericUnivariateSelect'\n",
      "    FEATURE_SELECTION -> 'sklearn.feature_selection.SelectPercentile'\n",
      "    FEATURE_SELECTION -> 'sklearn.feature_selection.SelectKBest'\n",
      "    FEATURE_SELECTION -> 'E'\n",
      "    TEXT_ENCODER -> 'sklearn.feature_extraction.text.CountVectorizer'\n",
      "    TEXT_ENCODER -> 'sklearn.feature_extraction.text.TfidfVectorizer'\n",
      "    TEXT_ENCODER -> 'main.MyEmbedder'\n",
      "    CATEGORICAL_ENCODER -> 'sklearn.preprocessing.OneHotEncoder'\n",
      "    CLASSIFICATION -> 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'\n",
      "    CLASSIFICATION -> 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'\n",
      "    CLASSIFICATION -> 'sklearn.ensemble.BaggingClassifier'\n",
      "    CLASSIFICATION -> 'sklearn.ensemble.ExtraTreesClassifier'\n",
      "    CLASSIFICATION -> 'sklearn.ensemble.GradientBoostingClassifier'\n",
      "    CLASSIFICATION -> 'sklearn.ensemble.RandomForestClassifier'\n",
      "    CLASSIFICATION -> 'sklearn.naive_bayes.BernoulliNB'\n",
      "    CLASSIFICATION -> 'sklearn.naive_bayes.GaussianNB'\n",
      "    CLASSIFICATION -> 'sklearn.naive_bayes.MultinomialNB'\n",
      "    CLASSIFICATION -> 'sklearn.neighbors.KNeighborsClassifier'\n",
      "    CLASSIFICATION -> 'sklearn.linear_model.LogisticRegression'\n",
      "    CLASSIFICATION -> 'sklearn.linear_model.PassiveAggressiveClassifier'\n",
      "    CLASSIFICATION -> 'sklearn.linear_model.SGDClassifier'\n",
      "    CLASSIFICATION -> 'sklearn.svm.LinearSVC'\n",
      "    CLASSIFICATION -> 'sklearn.svm.SVC'\n",
      "    CLASSIFICATION -> 'sklearn.tree.DecisionTreeClassifier'\n",
      "INFO:alpha_automl.grammar_loader:Creating game grammar\n",
      "INFO:alpha_automl.pipeline_search.Coach:------ITER 1------\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 1\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlopez/D3M/alpha-automl/alpha_automl/pipeline_search/pipeline/NNet.py:104: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  board = Variable(board, volatile=True)\n",
      "/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.505688\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 2\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: S\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: S -> IMPUTATION ENCODERS FEATURE_SCALING FEATURE_SELECTION CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.50579166\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 3\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: S\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: S -> IMPUTATION ENCODERS FEATURE_SCALING FEATURE_SELECTION CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.50558126\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 4\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: S\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: S -> IMPUTATION ENCODERS FEATURE_SCALING FEATURE_SELECTION CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.50551695\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 5\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: S\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: S -> IMPUTATION ENCODERS FEATURE_SCALING FEATURE_SELECTION CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.50512683\n",
      "INFO:alpha_automl.pipeline_search.Coach:COACH ACTION 0\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: S -> IMPUTATION ENCODERS FEATURE_SCALING FEATURE_SELECTION CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 1\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.505205\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 2\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.5055087\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 3\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.5051396\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 4\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_synthesis.pipeline_builder:New pipelined created:\n",
      "Pipeline(steps=[('sklearn.impute.SimpleImputer',\n",
      "                 SimpleImputer(strategy='most_frequent')),\n",
      "                ('sklearn.compose.ColumnTransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('sklearn.feature_extraction.text.CountVectorizer-text',\n",
      "                                                  CountVectorizer(), 0),\n",
      "                                                 ('sklearn.preprocessing.OneHotEncoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [1, 2, 3])])),\n",
      "                ('sklearn.preprocessing.MaxAbsScaler', MaxAbsScaler()),\n",
      "                ('sklearn.feature_selection.GenericUnivariateSelect',\n",
      "                 GenericUnivariateSelect()),\n",
      "                ('sklearn.discriminant_analysis.LinearDiscriminantAnalysis',\n",
      "                 LinearDiscriminantAnalysis())])\n",
      "WARNING:alpha_automl.scorer:Exception scoring a pipeline\n",
      "WARNING:alpha_automl.scorer:Detailed error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rlopez/D3M/alpha-automl/alpha_automl/scorer.py\", line 120, in score_pipeline\n",
      "    scores = cross_val_score(pipeline, X, y, cv=splitting_strategy, scoring=scoring, error_score='raise')\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 575, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/base.py\", line 565, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 845, in check_array\n",
      "    array = _ensure_sparse_format(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 522, in _ensure_sparse_format\n",
      "    raise TypeError(\n",
      "TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 5\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|ENCODERS|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_synthesis.pipeline_builder:New pipelined created:\n",
      "Pipeline(steps=[('sklearn.impute.SimpleImputer',\n",
      "                 SimpleImputer(strategy='most_frequent')),\n",
      "                ('sklearn.compose.ColumnTransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('sklearn.feature_extraction.text.CountVectorizer-text',\n",
      "                                                  CountVectorizer(), 0),\n",
      "                                                 ('sklearn.preprocessing.OneHotEncoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [1, 2, 3])])),\n",
      "                ('sklearn.preprocessing.MaxAbsScaler', MaxAbsScaler()),\n",
      "                ('sklearn.feature_selection.GenericUnivariateSelect',\n",
      "                 GenericUnivariateSelect()),\n",
      "                ('sklearn.naive_bayes.GaussianNB', GaussianNB())])\n",
      "WARNING:alpha_automl.scorer:Exception scoring a pipeline\n",
      "WARNING:alpha_automl.scorer:Detailed error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rlopez/D3M/alpha-automl/alpha_automl/scorer.py\", line 120, in score_pipeline\n",
      "    scores = cross_val_score(pipeline, X, y, cv=splitting_strategy, scoring=scoring, error_score='raise')\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 267, in fit\n",
      "    return self._partial_fit(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 428, in _partial_fit\n",
      "    X, y = self._validate_data(X, y, reset=first_call)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/base.py\", line 565, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 845, in check_array\n",
      "    array = _ensure_sparse_format(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 522, in _ensure_sparse_format\n",
      "    raise TypeError(\n",
      "TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
      "INFO:alpha_automl.pipeline_search.Coach:COACH ACTION 1\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: ENCODERS -> TEXT_ENCODER CATEGORICAL_ENCODER\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 1\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_synthesis.pipeline_builder:New pipelined created:\n",
      "Pipeline(steps=[('sklearn.impute.SimpleImputer',\n",
      "                 SimpleImputer(strategy='most_frequent')),\n",
      "                ('sklearn.compose.ColumnTransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('sklearn.feature_extraction.text.CountVectorizer-text',\n",
      "                                                  CountVectorizer(), 0),\n",
      "                                                 ('sklearn.preprocessing.OneHotEncoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [1, 2, 3])])),\n",
      "                ('sklearn.preprocessing.MaxAbsScaler', MaxAbsScaler()),\n",
      "                ('sklearn.feature_selection.GenericUnivariateSelect',\n",
      "                 GenericUnivariateSelect()),\n",
      "                ('sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis',\n",
      "                 QuadraticDiscriminantAnalysis())])\n",
      "WARNING:alpha_automl.scorer:Exception scoring a pipeline\n",
      "WARNING:alpha_automl.scorer:Detailed error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rlopez/D3M/alpha-automl/alpha_automl/scorer.py\", line 120, in score_pipeline\n",
      "    scores = cross_val_score(pipeline, X, y, cv=splitting_strategy, scoring=scoring, error_score='raise')\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 890, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/base.py\", line 565, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 845, in check_array\n",
      "    array = _ensure_sparse_format(\n",
      "  File \"/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 522, in _ensure_sparse_format\n",
      "    raise TypeError(\n",
      "TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 2\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.tree.DecisionTreeClassifier\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.tree.DecisionTreeClassifier\n",
      "INFO:alpha_automl.pipeline_synthesis.pipeline_builder:New pipelined created:\n",
      "Pipeline(steps=[('sklearn.impute.SimpleImputer',\n",
      "                 SimpleImputer(strategy='most_frequent')),\n",
      "                ('sklearn.compose.ColumnTransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('sklearn.feature_extraction.text.CountVectorizer-text',\n",
      "                                                  CountVectorizer(), 0),\n",
      "                                                 ('sklearn.preprocessing.OneHotEncoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [1, 2, 3])])),\n",
      "                ('sklearn.preprocessing.MaxAbsScaler', MaxAbsScaler()),\n",
      "                ('sklearn.feature_selection.GenericUnivariateSelect',\n",
      "                 GenericUnivariateSelect()),\n",
      "                ('sklearn.tree.DecisionTreeClassifier',\n",
      "                 DecisionTreeClassifier())])\n",
      "INFO:alpha_automl.scorer:Score: 0.434\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 3\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.automl_manager:Found new pipeline\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlopez/D3M/alpha-automl/alpha_automl/pipeline_search/pipeline/NNet.py:104: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  board = Variable(board, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:00:04, scoring...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlopez/opt/anaconda3/envs/alphaautoml/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.50545466\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 4\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 5\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: IMPUTATION|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.Coach:COACH ACTION 2\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: IMPUTATION -> sklearn.impute.SimpleImputer\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 1\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 2\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.50545925\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 3\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 4\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.naive_bayes.GaussianNB\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 5\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|FEATURE_SCALING|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.505154\n",
      "INFO:alpha_automl.pipeline_search.Coach:COACH ACTION 3\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SCALING -> sklearn.preprocessing.MaxAbsScaler\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 1\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 2\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.504794\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 3\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> sklearn.feature_extraction.text.CountVectorizer\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|sklearn.feature_extraction.text.CountVectorizer|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 4\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> main.MyEmbedder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|main.MyEmbedder|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.MCTS:Prediction 0.5053751\n",
      "INFO:alpha_automl.pipeline_search.MCTS:MCTS SIMULATION 5\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|FEATURE_SELECTION|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: FEATURE_SELECTION -> sklearn.feature_selection.GenericUnivariateSelect\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|CLASSIFICATION\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CLASSIFICATION -> sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|TEXT_ENCODER|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: TEXT_ENCODER -> main.MyEmbedder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|main.MyEmbedder|CATEGORICAL_ENCODER|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineLogic:MOVE ACTION: CATEGORICAL_ENCODER -> sklearn.preprocessing.OneHotEncoder\n",
      "INFO:alpha_automl.pipeline_search.pipeline.PipelineGame:PIPELINE: sklearn.impute.SimpleImputer|main.MyEmbedder|sklearn.preprocessing.OneHotEncoder|sklearn.preprocessing.MaxAbsScaler|sklearn.feature_selection.GenericUnivariateSelect|sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
      "INFO:alpha_automl.pipeline_synthesis.pipeline_builder:New pipelined created:\n",
      "Pipeline(steps=[('sklearn.impute.SimpleImputer',\n",
      "                 SimpleImputer(strategy='most_frequent')),\n",
      "                ('sklearn.compose.ColumnTransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('main.MyEmbedder-text',\n",
      "                                                  MyEmbedder(), 0),\n",
      "                                                 ('sklearn.preprocessing.OneHotEncoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [1, 2, 3])])),\n",
      "                ('sklearn.preprocessing.MaxAbsScaler', MaxAbsScaler()),\n",
      "                ('sklearn.feature_selection.GenericUnivariateSelect',\n",
      "                 GenericUnivariateSelect()),\n",
      "                ('sklearn.discriminant_analysis.LinearDiscriminantAnalysis',\n",
      "                 LinearDiscriminantAnalysis())])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ca710fc5d94d5da80a938c881ab3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.scorer:Score: 0.4252656090816475\n",
      "INFO:alpha_automl.automl_manager:Pipeline scored successfully, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.pipeline_synthesis.setup_search:Receiving signal, terminating process\n",
      "INFO:alpha_automl.automl_manager:Found 1 pipelines\n",
      "INFO:alpha_automl.automl_manager:Search done\n",
      "INFO:alpha_automl.automl_api:Found 1 pipelines\n"
     ]
    }
   ],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pipeline search is complete, we can display the leaderboard:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlopez/D3M/alpha-automl/alpha_automl/automl_api.py:220: FutureWarning: this method is deprecated in favour of `Styler.hide(axis=\"index\")`\n",
      "  return self.leaderboard.style.format(decimal_format).hide_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bb57c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_bb57c_level0_col0\" class=\"col_heading level0 col0\" >ranking</th>\n",
       "      <th id=\"T_bb57c_level0_col1\" class=\"col_heading level0 col1\" >pipeline</th>\n",
       "      <th id=\"T_bb57c_level0_col2\" class=\"col_heading level0 col2\" >accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_bb57c_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_bb57c_row0_col1\" class=\"data row0 col1\" >SimpleImputer, ColumnTransformer, CountVectorizer, OneHotEncoder, MaxAbsScaler, GenericUnivariateSelect, DecisionTreeClassifier</td>\n",
       "      <td id=\"T_bb57c_row0_col2\" class=\"data row0 col2\" >0.425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14d33d160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.plot_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.plot_comparison_pipelines()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
