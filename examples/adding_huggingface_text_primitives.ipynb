{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding HuggingFace Primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the class `AutoMLClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_automl import AutoMLClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Pipelines for CSV Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are generating pipelines for a CSV dataset. The sentiment dataset is used for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = pd.read_csv('datasets/sentiment/train_data.csv')\n",
    "test_dataset = pd.read_csv('datasets/sentiment/test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the target column from the features for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Grenada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Guatemala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text Time of Tweet  \\\n",
       "0                    I`d have responded, if I were going       morning   \n",
       "1          Sooo SAD I will miss you here in San Diego!!!          noon   \n",
       "2                              my boss is bullying me...         night   \n",
       "3                         what interview! leave me alone       morning   \n",
       "4       Sons of ****, why couldn`t they put them on t...          noon   \n",
       "...                                                  ...           ...   \n",
       "27476   wish we could come see u on Denver  husband l...         night   \n",
       "27477   I`ve wondered about rake to.  The client has ...       morning   \n",
       "27478   Yay good for both of you. Enjoy the break - y...          noon   \n",
       "27479                         But it was worth it  ****.         night   \n",
       "27480     All this flirting going on - The ATG smiles...       morning   \n",
       "\n",
       "      Age of User      Country  \n",
       "0            0-20  Afghanistan  \n",
       "1           21-30      Albania  \n",
       "2           31-45      Algeria  \n",
       "3           46-60      Andorra  \n",
       "4           60-70       Angola  \n",
       "...           ...          ...  \n",
       "27476       31-45        Ghana  \n",
       "27477       46-60       Greece  \n",
       "27478       60-70      Grenada  \n",
       "27479      70-100    Guatemala  \n",
       "27480        0-20       Guinea  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = 'sentiment'\n",
    "X_train = train_dataset.drop(columns=[target_column])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the target column for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment\n",
       "0       neutral\n",
       "1      negative\n",
       "2      negative\n",
       "3      negative\n",
       "4      negative\n",
       "...         ...\n",
       "27476  negative\n",
       "27477  negative\n",
       "27478  positive\n",
       "27479  positive\n",
       "27480   neutral\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_dataset[[target_column]]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding New Primitives into AlphaAutoML's Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLClassifier(time_bound=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_automl.wrapper_primitives.huggingface_text import HuggingfaceTextTransformer\n",
    "\n",
    "my_tweet_embedder = HuggingfaceTextTransformer('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "my_sentiment_embedder = HuggingfaceTextTransformer('allenai/reviews_roberta_base')\n",
    "automl.add_primitives([(my_tweet_embedder, 'TEXT_ENCODER')])\n",
    "automl.add_primitives([(my_sentiment_embedder, 'TEXT_ENCODER')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:00:03, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:00:03, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:00:04, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.31596565274341437\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:02:07, scoring...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib:matplotlib data path: /ext3/miniconda3/lib/python3.10/site-packages/matplotlib/mpl-data\n",
      "DEBUG:matplotlib:CONFIGDIR=/home/yfw215/.config/matplotlib\n",
      "DEBUG:matplotlib:interactive is False\n",
      "DEBUG:matplotlib:platform is linux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.5972929704555378\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:55:17, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4217726677339543\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:55:18, scoring...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pipeline search is complete, we can display the leaderboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_eb8b2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_eb8b2_level0_col0\" class=\"col_heading level0 col0\" >ranking</th>\n",
       "      <th id=\"T_eb8b2_level0_col1\" class=\"col_heading level0 col1\" >pipeline</th>\n",
       "      <th id=\"T_eb8b2_level0_col2\" class=\"col_heading level0 col2\" >accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_eb8b2_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_eb8b2_row0_col1\" class=\"data row0 col1\" >SimpleImputer, ColumnTransformer, HuggingfaceTextTransformer, OneHotEncoder, MaxAbsScaler, DecisionTreeClassifier</td>\n",
       "      <td id=\"T_eb8b2_row0_col2\" class=\"data row0 col2\" >0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb8b2_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_eb8b2_row1_col1\" class=\"data row1 col1\" >SimpleImputer, ColumnTransformer, CountVectorizer, OneHotEncoder, MaxAbsScaler, DecisionTreeClassifier</td>\n",
       "      <td id=\"T_eb8b2_row1_col2\" class=\"data row1 col2\" >0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb8b2_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_eb8b2_row2_col1\" class=\"data row2 col1\" >SimpleImputer, ColumnTransformer, HuggingfaceTextTransformer, OneHotEncoder, MaxAbsScaler, GenericUnivariateSelect, DecisionTreeClassifier</td>\n",
       "      <td id=\"T_eb8b2_row2_col2\" class=\"data row2 col2\" >0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb8b2_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_eb8b2_row3_col1\" class=\"data row3 col1\" >SimpleImputer, ColumnTransformer, HuggingfaceTextTransformer, OneHotEncoder, MaxAbsScaler, GenericUnivariateSelect, PassiveAggressiveClassifier</td>\n",
       "      <td id=\"T_eb8b2_row3_col2\" class=\"data row3 col2\" >0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb8b2_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_eb8b2_row4_col1\" class=\"data row4 col1\" >SimpleImputer, ColumnTransformer, CountVectorizer, OneHotEncoder, MaxAbsScaler, GenericUnivariateSelect, DecisionTreeClassifier</td>\n",
       "      <td id=\"T_eb8b2_row4_col2\" class=\"data row4 col2\" >0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb8b2_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_eb8b2_row5_col1\" class=\"data row5 col1\" >SimpleImputer, ColumnTransformer, CountVectorizer, OneHotEncoder, MaxAbsScaler, GenericUnivariateSelect, LogisticRegression</td>\n",
       "      <td id=\"T_eb8b2_row5_col2\" class=\"data row5 col2\" >0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb8b2_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_eb8b2_row6_col1\" class=\"data row6 col1\" >SimpleImputer, ColumnTransformer, TfidfVectorizer, OneHotEncoder, MaxAbsScaler, GenericUnivariateSelect, DecisionTreeClassifier</td>\n",
       "      <td id=\"T_eb8b2_row6_col2\" class=\"data row6 col2\" >0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eb8b2_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_eb8b2_row7_col1\" class=\"data row7 col1\" >SimpleImputer, ColumnTransformer, CountVectorizer, OneHotEncoder, MaxAbsScaler, GenericUnivariateSelect, PassiveAggressiveClassifier</td>\n",
       "      <td id=\"T_eb8b2_row7_col2\" class=\"data row7 col2\" >0.316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14e624ca3ac0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.plot_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explore the produced pipelines, we can use [PipelineProfiler](https://github.com/VIDA-NYU/PipelineVis). PipelineProfiler is a visualization that enables users to compare and explore the pipelines generated by the AlphaAutoML system.\n",
    "\n",
    "After the pipeline search process is completed, we can use PipelineProfiler with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.plot_comparison_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the target column from the features for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Nicaragua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>All alone in this old house again.  Thanks for...</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Niger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>I know what you mean. My little dog is sinkin...</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>_sutra what is your next youtube video gonna b...</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>North Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>North Macedonia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3534 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Time of Tweet  \\\n",
       "0     Last session of the day  http://twitpic.com/67ezh       morning   \n",
       "1      Shanghai is also really exciting (precisely -...          noon   \n",
       "2     Recession hit Veronique Branquinho, she has to...         night   \n",
       "3                                           happy bday!       morning   \n",
       "4                http://twitpic.com/4w75p - I like it!!          noon   \n",
       "...                                                 ...           ...   \n",
       "3529  its at 3 am, im very tired but i can`t sleep  ...          noon   \n",
       "3530  All alone in this old house again.  Thanks for...         night   \n",
       "3531   I know what you mean. My little dog is sinkin...       morning   \n",
       "3532  _sutra what is your next youtube video gonna b...          noon   \n",
       "3533   http://twitpic.com/4woj2 - omgssh  ang cute n...         night   \n",
       "\n",
       "     Age of User          Country  \n",
       "0           0-20      Afghanistan  \n",
       "1          21-30          Albania  \n",
       "2          31-45          Algeria  \n",
       "3          46-60          Andorra  \n",
       "4          60-70           Angola  \n",
       "...          ...              ...  \n",
       "3529       21-30        Nicaragua  \n",
       "3530       31-45            Niger  \n",
       "3531       46-60          Nigeria  \n",
       "3532       60-70      North Korea  \n",
       "3533      70-100  North Macedonia  \n",
       "\n",
       "[3534 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_dataset.drop(columns=[target_column])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the target column for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3534 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment\n",
       "0      neutral\n",
       "1     positive\n",
       "2     negative\n",
       "3     positive\n",
       "4     positive\n",
       "...        ...\n",
       "3529  negative\n",
       "3530  positive\n",
       "3531  negative\n",
       "3532  positive\n",
       "3533  positive\n",
       "\n",
       "[3534 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test_dataset[[target_column]]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline predictions are accessed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative', ..., 'negative', 'positive',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline can be evaluated against a held out dataset with the function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.automl_api:Metric: accuracy_score, Score: 0.6706281833616299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'accuracy_score', 'score': 0.6706281833616299}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
