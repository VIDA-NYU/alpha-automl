{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding HuggingFace Primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the class `AutoMLClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_automl import AutoMLClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Pipelines for CSV Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are generating pipelines for a CSV dataset. The sentiment dataset is used for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'tmp/'\n",
    "train_dataset = pd.read_csv('datasets/sentiment/train_data.csv')\n",
    "test_dataset = pd.read_csv('datasets/sentiment/test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the target column from the features for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Ghana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Grenada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Guatemala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Guinea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text Time of Tweet   \n",
       "0                    I`d have responded, if I were going       morning  \\\n",
       "1          Sooo SAD I will miss you here in San Diego!!!          noon   \n",
       "2                              my boss is bullying me...         night   \n",
       "3                         what interview! leave me alone       morning   \n",
       "4       Sons of ****, why couldn`t they put them on t...          noon   \n",
       "...                                                  ...           ...   \n",
       "27476   wish we could come see u on Denver  husband l...         night   \n",
       "27477   I`ve wondered about rake to.  The client has ...       morning   \n",
       "27478   Yay good for both of you. Enjoy the break - y...          noon   \n",
       "27479                         But it was worth it  ****.         night   \n",
       "27480     All this flirting going on - The ATG smiles...       morning   \n",
       "\n",
       "      Age of User      Country  \n",
       "0            0-20  Afghanistan  \n",
       "1           21-30      Albania  \n",
       "2           31-45      Algeria  \n",
       "3           46-60      Andorra  \n",
       "4           60-70       Angola  \n",
       "...           ...          ...  \n",
       "27476       31-45        Ghana  \n",
       "27477       46-60       Greece  \n",
       "27478       60-70      Grenada  \n",
       "27479      70-100    Guatemala  \n",
       "27480        0-20       Guinea  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = 'sentiment'\n",
    "X_train = train_dataset.drop(columns=[target_column])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the target column for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment\n",
       "0       neutral\n",
       "1      negative\n",
       "2      negative\n",
       "3      negative\n",
       "4      negative\n",
       "...         ...\n",
       "27476  negative\n",
       "27477  negative\n",
       "27478  positive\n",
       "27479  positive\n",
       "27480   neutral\n",
       "\n",
       "[27481 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_dataset[[target_column]]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding New Primitives into AlphaAutoML's Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLClassifier(output_path, time_bound=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the fasttext module if not already downloaded\n",
    "import os\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "fasttext_model_path = os.getcwd() + '/cc.en.300.bin' # change this accordingly to the path where the model is downloaded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fasttext Module and adding this as a primitive to automl\n",
    "\n",
    "'''\n",
    "from alpha_automl.wrapper_primitives.fasttext import FastTextEmbedder \n",
    "fasttext_embedder = FastTextEmbedder(fasttext_model_path)\n",
    "automl.add_primitives([(fasttext_embedder, 'TEXT_ENCODER')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching  Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:00:03, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:00:04, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:00:05, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.31596565274341437\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:00:25, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.36646776306214524\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:01:00, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4217726677339543\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:01:02, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4045990394411294\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:01:36, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6277106680250327\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:01:48, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.43559889390190654\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:02:34, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.31596565274341437\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:02:35, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6186872362101586\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:02:39, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4102750691311308\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:03:09, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.5280163003929559\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:03:10, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:03:10, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.36675884150778637\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:03:33, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:03:35, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6787949352350459\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:03:38, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:03:41, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4111483044680541\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:04:03, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6144665987483627\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:04:04, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:04:30, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4142046281472857\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:04:55, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:04:57, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:04:57, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.605006549265027\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:04, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.3169844273031582\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:05, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6453209139863193\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:05, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:06, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4037258041042061\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:06, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:07, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.5613447824188619\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:29, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4222092854024159\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:30, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6917479260660748\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:31, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.5268519866103915\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:31, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.42337359918498035\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:33, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.39790423519138407\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:34, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6409547373017028\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:46, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:54, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:55, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4252656090816475\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:05:56, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6718090525396594\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:06:42, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4174064910493378\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:07:04, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6611846892737593\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:07:21, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.4450589433852423\n",
      "INFO:alpha_automl.automl_api:Found pipeline, time=0:07:44, scoring...\n",
      "INFO:alpha_automl.automl_api:Scored pipeline, score=0.6406636588560617\n"
     ]
    }
   ],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pipeline search is complete, we can display the leaderboard:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "automl.plot_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.plot_comparison_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl-env",
   "language": "python",
   "name": "automl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
